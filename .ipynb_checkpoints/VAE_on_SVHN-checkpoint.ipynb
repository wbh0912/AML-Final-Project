{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "daq3CdxyD9tC"
   },
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sys import exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujXVFJKz5Iao"
   },
   "source": [
    "# **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QqBx7laLuaF7"
   },
   "outputs": [],
   "source": [
    "# Make sure you upload training and test data before running this cell if you are using colab\n",
    "# The dataset can be founnd here: http://ufldl.stanford.edu/housenumbers/\n",
    "# We got our insights of creating dataset class here: https://github.com/wbh0912/VAE_SVHN/blob/master/dataset/dataset_svhn.py\n",
    "\n",
    "# Images of the red channel\n",
    "\n",
    "class SVHNDataset_R:\n",
    "    def __init__(self, db_path='/content', use_extra=False):\n",
    "        print(\"Loading files\")\n",
    "        self.data_dims = [32, 32]\n",
    "        self.name = \"svhn\"\n",
    "        self.train_file = os.path.join(db_path, \"train_32x32.mat\") # path for train file on VM\n",
    "        self.test_file = os.path.join(db_path, \"test_32x32.mat\") # path for test file on VM\n",
    "        print(self.train_file)\n",
    "        \n",
    "        # Load training images\n",
    "        if os.path.isfile(self.train_file):\n",
    "            mat = sio.loadmat(self.train_file) # entire train file\n",
    "            self.train_label = mat['y']\n",
    "            self.train_image = mat['X'] # 32 * 32 * 3 * 73257\n",
    "            self.train_image = np.transpose(self.train_image, [3, 0, 1, 2])[:,:,:,0] # take the first channel\n",
    "            self.train_image = np.clip(self.train_image / 255.0, a_min=0.0, a_max=1.0)\n",
    "        else:\n",
    "            print(\"SVHN dataset train files not found\")\n",
    "            exit(-1)\n",
    "        self.train_batch_ptr = 0\n",
    "        self.train_size = self.train_image.shape[0]\n",
    "\n",
    "        if os.path.isfile(self.test_file):\n",
    "            mat = sio.loadmat(self.test_file) # entire test file\n",
    "            self.test_label = mat['y']\n",
    "            self.test_image = mat['X'].astype(np.float32) \n",
    "            self.test_image = np.transpose(self.test_image, [3, 0, 1, 2])[:,:,:,0]\n",
    "            self.test_image = np.clip(self.test_image / 255.0, a_min=0.0, a_max=1.0)\n",
    "        else:\n",
    "            print(\"SVHN dataset test files not found\")\n",
    "            exit(-1)\n",
    "        self.test_batch_ptr = 0\n",
    "        self.test_size = self.test_image.shape[0]\n",
    "        print(\"SVHN_R loaded into memory\")\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        prev_batch_ptr = self.train_batch_ptr\n",
    "        self.train_batch_ptr += batch_size\n",
    "        if self.train_batch_ptr > self.train_image.shape[0]:\n",
    "            self.train_batch_ptr = batch_size\n",
    "            prev_batch_ptr = 0\n",
    "        return self.train_image[prev_batch_ptr:self.train_batch_ptr, :, :]\n",
    "\n",
    "    def batch_by_index(self, batch_start, batch_end):\n",
    "        return self.train_image[batch_start:batch_end, :, :]\n",
    "\n",
    "    def next_test_batch(self, batch_size):\n",
    "        prev_batch_ptr = self.test_batch_ptr\n",
    "        self.test_batch_ptr += batch_size\n",
    "        if self.test_batch_ptr > self.test_image.shape[0]:\n",
    "            self.test_batch_ptr = batch_size\n",
    "            prev_batch_ptr = 0\n",
    "        return self.test_image[prev_batch_ptr:self.test_batch_ptr, :, :], self.test_label[prev_batch_ptr:self.test_batch_ptr]\n",
    "\n",
    "    def reset(self):\n",
    "        self.train_batch_ptr = 0\n",
    "        self.test_batch_ptr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KecUjv3YLAap"
   },
   "outputs": [],
   "source": [
    "# Images of the green channel\n",
    "\n",
    "class SVHNDataset_G:\n",
    "    def __init__(self, db_path='/content', use_extra=False):\n",
    "        print(\"Loading files\")\n",
    "        self.data_dims = [32, 32]\n",
    "        self.name = \"svhn\"\n",
    "        self.train_file = os.path.join(db_path, \"train_32x32.mat\") # path for train file on VM\n",
    "        self.test_file = os.path.join(db_path, \"test_32x32.mat\") # path for test file on VM\n",
    "        print(self.train_file)\n",
    "        \n",
    "        # Load training images\n",
    "        if os.path.isfile(self.train_file):\n",
    "            mat = sio.loadmat(self.train_file) # entire train file\n",
    "            self.train_label = mat['y']\n",
    "            self.train_image = mat['X'].astype(np.float32) # 32 * 32 * 3 * 73257\n",
    "            self.train_image = np.transpose(self.train_image, [3, 0, 1, 2])[:,:,:,1] # take the 2nd channel\n",
    "            self.train_image = np.clip(self.train_image / 255.0, a_min=0.0, a_max=1.0)\n",
    "        else:\n",
    "            print(\"SVHN dataset train files not found\")\n",
    "            exit(-1)\n",
    "        self.train_batch_ptr = 0\n",
    "        self.train_size = self.train_image.shape[0]\n",
    "\n",
    "        if os.path.isfile(self.test_file):\n",
    "            mat = sio.loadmat(self.test_file) # entire test file\n",
    "            self.test_label = mat['y']\n",
    "            self.test_image = mat['X'].astype(np.float32) \n",
    "            self.test_image = np.transpose(self.test_image, [3, 0, 1, 2])[:,:,:,1]\n",
    "            self.test_image = np.clip(self.test_image / 255.0, a_min=0.0, a_max=1.0)\n",
    "        else:\n",
    "            print(\"SVHN dataset test files not found\")\n",
    "            exit(-1)\n",
    "        self.test_batch_ptr = 0\n",
    "        self.test_size = self.test_image.shape[0]\n",
    "        print(\"SVHN_G loaded into memory\")\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        prev_batch_ptr = self.train_batch_ptr\n",
    "        self.train_batch_ptr += batch_size\n",
    "        if self.train_batch_ptr > self.train_image.shape[0]:\n",
    "            self.train_batch_ptr = batch_size\n",
    "            prev_batch_ptr = 0\n",
    "        return self.train_image[prev_batch_ptr:self.train_batch_ptr, :, :]\n",
    "\n",
    "    def batch_by_index(self, batch_start, batch_end):\n",
    "        return self.train_image[batch_start:batch_end, :, :]\n",
    "\n",
    "    def next_test_batch(self, batch_size):\n",
    "        prev_batch_ptr = self.test_batch_ptr\n",
    "        self.test_batch_ptr += batch_size\n",
    "        if self.test_batch_ptr > self.test_image.shape[0]:\n",
    "            self.test_batch_ptr = batch_size\n",
    "            prev_batch_ptr = 0\n",
    "        return self.test_image[prev_batch_ptr:self.test_batch_ptr, :, :], self.test_label[prev_batch_ptr:self.test_batch_ptr]\n",
    "\n",
    "    def reset(self):\n",
    "        self.train_batch_ptr = 0\n",
    "        self.test_batch_ptr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "olInk216L2yS"
   },
   "outputs": [],
   "source": [
    "# Images of the blue channel\n",
    "\n",
    "class SVHNDataset_B:\n",
    "    def __init__(self, db_path='/content', use_extra=False):\n",
    "        print(\"Loading files\")\n",
    "        self.data_dims = [32, 32]\n",
    "        self.name = \"svhn\"\n",
    "        self.train_file = os.path.join(db_path, \"train_32x32.mat\") # path for train file on VM\n",
    "        self.test_file = os.path.join(db_path, \"test_32x32.mat\") # path for test file on VM\n",
    "        print(self.train_file)\n",
    "        \n",
    "        # Load training images\n",
    "        if os.path.isfile(self.train_file):\n",
    "            mat = sio.loadmat(self.train_file) # entire train file\n",
    "            self.train_label = mat['y']\n",
    "            self.train_image = mat['X'].astype(np.float32) # 32 * 32 * 3 * 73257\n",
    "            self.train_image = np.transpose(self.train_image, [3, 0, 1, 2])[:,:,:,2] # take the 3rd channel\n",
    "            self.train_image = np.clip(self.train_image / 255.0, a_min=0.0, a_max=1.0)\n",
    "        else:\n",
    "            print(\"SVHN dataset train files not found\")\n",
    "            exit(-1)\n",
    "        self.train_batch_ptr = 0\n",
    "        self.train_size = self.train_image.shape[0]\n",
    "\n",
    "        if os.path.isfile(self.test_file):\n",
    "            mat = sio.loadmat(self.test_file) # entire test file\n",
    "            self.test_label = mat['y']\n",
    "            self.test_image = mat['X'].astype(np.float32) \n",
    "            self.test_image = np.transpose(self.test_image, [3, 0, 1, 2])[:,:,:,2]\n",
    "            self.test_image = np.clip(self.test_image / 255.0, a_min=0.0, a_max=1.0)\n",
    "        else:\n",
    "            print(\"SVHN dataset test files not found\")\n",
    "            exit(-1)\n",
    "        self.test_batch_ptr = 0\n",
    "        self.test_size = self.test_image.shape[0]\n",
    "        print(\"SVHN_B loaded into memory\")\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        prev_batch_ptr = self.train_batch_ptr\n",
    "        self.train_batch_ptr += batch_size\n",
    "        if self.train_batch_ptr > self.train_image.shape[0]:\n",
    "            self.train_batch_ptr = batch_size\n",
    "            prev_batch_ptr = 0\n",
    "        return self.train_image[prev_batch_ptr:self.train_batch_ptr, :, :]\n",
    "\n",
    "    def batch_by_index(self, batch_start, batch_end):\n",
    "        return self.train_image[batch_start:batch_end, :, :]\n",
    "\n",
    "    def next_test_batch(self, batch_size):\n",
    "        prev_batch_ptr = self.test_batch_ptr\n",
    "        self.test_batch_ptr += batch_size\n",
    "        if self.test_batch_ptr > self.test_image.shape[0]:\n",
    "            self.test_batch_ptr = batch_size\n",
    "            prev_batch_ptr = 0\n",
    "        return self.test_image[prev_batch_ptr:self.test_batch_ptr, :, :], self.test_label[prev_batch_ptr:self.test_batch_ptr]\n",
    "\n",
    "    def reset(self):\n",
    "        self.train_batch_ptr = 0\n",
    "        self.test_batch_ptr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "XVh-EzbDwXQG",
    "outputId": "0b1716ec-e954-4082-ec51-7be4cccc5788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Loading files\n",
      "./train_32x32.mat\n",
      "SVHN_R loaded into memory\n",
      "Loading files\n",
      "./train_32x32.mat\n",
      "SVHN_G loaded into memory\n",
      "Loading files\n",
      "./train_32x32.mat\n",
      "SVHN_B loaded into memory\n"
     ]
    }
   ],
   "source": [
    "# # Load SVHN Data\n",
    "print(os.getcwd())\n",
    "dataset_R= SVHNDataset_R('.')\n",
    "dataset_G= SVHNDataset_G('.')\n",
    "dataset_B= SVHNDataset_B('.')\n",
    "n_samples=dataset_R.train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2L2JKI555RId"
   },
   "source": [
    "# **Build VAE model and train function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9up0T2IEFnlk"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# Some Settings\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wOWlLD8dUrlc"
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    https://jmetzen.github.io/2015-11-27/vae.html\n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture, transfer_fct=tf.nn.relu, \n",
    "                 learning_rate=0.001, batch_size=100):\n",
    "        self.network_architecture = network_architecture\n",
    "        self.transfer_fct = transfer_fct\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        # tf Graph input\n",
    "        self.x = tf.placeholder(tf.float32, [None, network_architecture[\"n_input\"]])\n",
    "        \n",
    "        # Create autoencoder network\n",
    "        self._create_network()\n",
    "        # Define loss function based variational upper-bound and \n",
    "        # corresponding optimizer\n",
    "        self._create_loss_optimizer()\n",
    "        \n",
    "        # Initializing the tensor flow variables\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "    \n",
    "    def _create_network(self):\n",
    "        # Initialize autoencode network weights and biases\n",
    "        network_weights = self._initialize_weights(**self.network_architecture)\n",
    "\n",
    "        # Use recognition network to determine mean and \n",
    "        # (log) variance of Gaussian distribution in latent\n",
    "        # space\n",
    "        self.z_mean, self.z_log_sigma_sq = self._recognition_network(network_weights[\"weights_recog\"], \n",
    "                                      network_weights[\"biases_recog\"])\n",
    "\n",
    "        # Draw one sample z from Gaussian distribution\n",
    "        n_z = self.network_architecture[\"n_z\"]\n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        # z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "\n",
    "        # Use generator to determine mean of\n",
    "        # Bernoulli distribution of reconstructed input\n",
    "        self.x_reconstr_mean = self._generator_network(network_weights[\"weights_gener\"],\n",
    "                                    network_weights[\"biases_gener\"])\n",
    "            \n",
    "    def _initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        all_weights = dict()\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(initializer(shape = [n_input, n_hidden_recog_1])),\n",
    "            'h2': tf.Variable(initializer(shape = [n_hidden_recog_1, n_hidden_recog_2])),\n",
    "            'out_mean': tf.Variable(initializer(shape = [n_hidden_recog_2, n_z])),\n",
    "            'out_log_sigma': tf.Variable(initializer(shape = [n_hidden_recog_2, n_z]))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(initializer(shape = [n_z, n_hidden_gener_1])),\n",
    "            'h2': tf.Variable(initializer(shape = [n_hidden_gener_1, n_hidden_gener_2])),\n",
    "            'out_mean': tf.Variable(initializer(shape = [n_hidden_gener_2, n_input])),\n",
    "            'out_log_sigma': tf.Variable(initializer(shape = [n_hidden_gener_2, n_input]))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        return all_weights\n",
    "            \n",
    "    def _recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2']))\n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean'])\n",
    "        z_log_sigma_sq = tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "\n",
    "    def _generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto a Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        x_reconstr_mean = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))        \n",
    "        return x_reconstr_mean\n",
    "            \n",
    "    def _create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluation of log(0.0)\n",
    "        reconstr_loss = -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           1)\n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n",
    "                                           - tf.square(self.z_mean) \n",
    "                                           - tf.exp(self.z_log_sigma_sq), 1)\n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "        \n",
    "        # Use ADAM optimizer\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5PMSQ6G0SOi5"
   },
   "outputs": [],
   "source": [
    "# Train Function\n",
    "def train_R(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=1):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs= dataset_R.next_batch(batch_size).reshape(batch_size,1024)\n",
    "            # Fit training using batch data\n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    return vae\n",
    "\n",
    "def train_G(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=1):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs= dataset_G.next_batch(batch_size).reshape(batch_size,1024)\n",
    "            # Fit training using batch data\n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    return vae\n",
    "\n",
    "def train_B(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=1):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs= dataset_B.next_batch(batch_size).reshape(batch_size,1024)\n",
    "            # Fit training using batch data\n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average loss\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HIpcUTb54riM"
   },
   "source": [
    "# **Comparison between different latent space dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hX-gyzjrFzL3"
   },
   "outputs": [],
   "source": [
    "# default architecture\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=500, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=20)  # dimensionality of latent space\n",
    "\n",
    "vae_20_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_20_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_20_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JbgC7yJWXEvV"
   },
   "outputs": [],
   "source": [
    "# test samples\n",
    "x_sample_R = dataset_R.next_test_batch(100)[0]\n",
    "x_sample_G = dataset_G.next_test_batch(100)[0]\n",
    "x_sample_B = dataset_B.next_test_batch(100)[0]\n",
    "\n",
    "# Combine RGB channels\n",
    "x_sample = np.transpose(np.stack((x_sample_R, x_sample_G, x_sample_B)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MEjjsVtVkNi0"
   },
   "outputs": [],
   "source": [
    "# test outputs\n",
    "x_reconstruct_R = vae_20_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G = vae_20_R.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B = vae_20_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# Combine sample arrays\n",
    "x_reconstruct = np.transpose(np.stack((x_reconstruct_R, x_reconstruct_G, x_reconstruct_B)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KxZN2exgmifU"
   },
   "outputs": [],
   "source": [
    "# 128D latent space\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=500, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=128)  # dimensionality of latent space\n",
    "\n",
    "vae_128_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_128_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_128_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_HS5UXCpqGo_"
   },
   "outputs": [],
   "source": [
    "# test outputs of 128D\n",
    "x_reconstruct_R_128 = vae_128_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_128 = vae_128_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_128 = vae_128_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_128 = np.transpose(np.stack((x_reconstruct_R_128, x_reconstruct_G_128, x_reconstruct_B_128)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K0l6akQJucUC"
   },
   "outputs": [],
   "source": [
    "# 512D latent space\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=500, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=512)  # dimensionality of latent space\n",
    "\n",
    "vae_512_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_512_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_512_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "tUBMggVGv4nd"
   },
   "outputs": [],
   "source": [
    "# test outputs of 512D\n",
    "x_reconstruct_R_512 = vae_512_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_512 = vae_512_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_512 = vae_512_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_512 = np.transpose(np.stack((x_reconstruct_R_512, x_reconstruct_G_512, x_reconstruct_B_512)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "com4iq1I0fAJ"
   },
   "outputs": [],
   "source": [
    "# 10D latent space\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=500, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=10)  # dimensionality of latent space\n",
    "\n",
    "vae_10_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_10_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_10_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9RrvytXG0l9o"
   },
   "outputs": [],
   "source": [
    "# test outputs of 10D\n",
    "x_reconstruct_R_10 = vae_10_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_10 = vae_10_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_10 = vae_10_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_10 = np.transpose(np.stack((x_reconstruct_R_10, x_reconstruct_G_10, x_reconstruct_B_10)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MMlq8Oft50-A"
   },
   "outputs": [],
   "source": [
    "# Final change of latent dimension comparison\n",
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 5, 5*i + 1)\n",
    "    plt.imshow(x_sample[i])\n",
    "    plt.title(\"Test input\")\n",
    "    plt.subplot(5, 5, 5*i + 2)\n",
    "    plt.imshow(x_reconstruct_10[i])\n",
    "    plt.title(\"Z = 10\")\n",
    "    plt.subplot(5, 5, 5*i + 3)\n",
    "    plt.imshow(x_reconstruct[i])\n",
    "    plt.title(\"Z = 20\")\n",
    "    plt.subplot(5, 5, 5*i + 4)\n",
    "    plt.imshow(x_reconstruct_128[i])\n",
    "    plt.title(\"Z = 128\")\n",
    "    plt.subplot(5, 5, 5*i + 5)\n",
    "    plt.imshow(x_reconstruct_512[i])\n",
    "    plt.title(\"Z = 512\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('change of latent dimension') # this line is used to save image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpUSnrvR5YPY"
   },
   "source": [
    "# **Comparison between different layer width**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pkEduEZj9HMh"
   },
   "outputs": [],
   "source": [
    "# amount of neurons = 200\n",
    "network_architecture = dict(n_hidden_recog_1=200, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=200, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=200, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=200, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=20)  # dimensionality of latent space\n",
    "\n",
    "vae_arch200_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch200_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch200_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AOhCxgAA_GgK"
   },
   "outputs": [],
   "source": [
    "# test outputs of neurons = 200\n",
    "x_reconstruct_R_arch200 = vae_arch200_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_arch200 = vae_arch200_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_arch200 = vae_arch200_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_arch200 = np.transpose(np.stack((x_reconstruct_R_arch200, x_reconstruct_G_arch200, x_reconstruct_B_arch200)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "e50_11J6CHhV"
   },
   "outputs": [],
   "source": [
    "# amount of neurons = 1000\n",
    "network_architecture = dict(n_hidden_recog_1=1000, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=1000, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=20)  # dimensionality of latent space\n",
    "\n",
    "vae_arch1000_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch1000_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch1000_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AxsBoTZhCSb-"
   },
   "outputs": [],
   "source": [
    "# test outputs of neurons = 1000\n",
    "x_reconstruct_R_arch1000 = vae_arch1000_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_arch1000 = vae_arch1000_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_arch1000 = vae_arch1000_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_arch1000 = np.transpose(np.stack((x_reconstruct_R_arch1000, x_reconstruct_G_arch1000, x_reconstruct_B_arch1000)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GvlSDSAAIw5s"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 4, 4*i + 1)\n",
    "    plt.imshow(x_sample[i+40])\n",
    "    plt.title(\"Test input\")\n",
    "    plt.subplot(5, 4, 4*i + 2)\n",
    "    plt.imshow(x_reconstruct_arch200[i+40])\n",
    "    plt.title(\"100 Neurons\")\n",
    "    plt.subplot(5, 4, 4*i + 3)\n",
    "    plt.imshow(x_reconstruct[i+40])\n",
    "    plt.title(\"500 Neurons\")\n",
    "    plt.subplot(5, 4, 4*i + 4)\n",
    "    plt.imshow(x_reconstruct_arch1000[i+40])\n",
    "    plt.title(\"1000 Neurons\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('change of neuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4Yrs28c5xLl"
   },
   "source": [
    "# **Comparison between different network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ApiA0d7HLU-X"
   },
   "outputs": [],
   "source": [
    "# different neuron per layer\n",
    "# 500-1000 encoder\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=1000, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=1000, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=20)  # dimensionality of latent space\n",
    "\n",
    "vae_arch510_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch510_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch510_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aGRn17yvOsSG"
   },
   "outputs": [],
   "source": [
    "# test outputs of 500-1000 encoder\n",
    "x_reconstruct_R_arch510 = vae_arch510_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_arch510 = vae_arch510_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_arch510 = vae_arch510_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_arch510 = np.transpose(np.stack((x_reconstruct_R_arch510, x_reconstruct_G_arch510, x_reconstruct_B_arch510)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jnHaOOs2TEox"
   },
   "outputs": [],
   "source": [
    "# different neuron per layer\n",
    "# 500-200 encoder\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=200, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=200, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=20)  # dimensionality of latent space\n",
    "\n",
    "vae_arch52_R = train_R(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch52_G = train_G(network_architecture, training_epochs=10, batch_size=100)\n",
    "vae_arch52_B = train_B(network_architecture, training_epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LQYf1TCUTVxQ"
   },
   "outputs": [],
   "source": [
    "# test outputs 500-200 encoder\n",
    "x_reconstruct_R_arch52 = vae_arch52_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_arch52 = vae_arch52_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_arch52 = vae_arch52_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_arch52 = np.transpose(np.stack((x_reconstruct_R_arch52, x_reconstruct_G_arch52, x_reconstruct_B_arch52)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uV5cf6YT0YuW"
   },
   "outputs": [],
   "source": [
    "# unequal layer width comparison\n",
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 4, 4*i + 1)\n",
    "    plt.imshow(x_sample[i+20])\n",
    "    plt.title(\"Test input\")\n",
    "    plt.subplot(5, 4, 4*i + 2)\n",
    "    plt.imshow(x_reconstruct_arch510[i+20])\n",
    "    plt.title(\"500-1000\")\n",
    "    plt.subplot(5, 4, 4*i + 3)\n",
    "    plt.imshow(x_reconstruct[i+20])\n",
    "    plt.title(\"500-500\")\n",
    "    plt.subplot(5, 4, 4*i + 4)\n",
    "    plt.imshow(x_reconstruct_arch52[i+20])\n",
    "    plt.title(\"500-200\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('change of arch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7FB6Zrm6L49"
   },
   "source": [
    "# **Comparison between different numbers of epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fBjyoHmz2IVC"
   },
   "outputs": [],
   "source": [
    "# epoch = 20\n",
    "network_architecture = dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "                            n_hidden_recog_2=500, # 2nd layer encoder neurons\n",
    "                            n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "                            n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "                            n_input=1024, # \n",
    "                            n_z=20)  # dimensionality of latent space\n",
    "\n",
    "vae_ep20_R = train_R(network_architecture, training_epochs=20, batch_size=100)\n",
    "vae_ep20_G = train_G(network_architecture, training_epochs=20, batch_size=100)\n",
    "vae_ep20_B = train_B(network_architecture, training_epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mMUBFWfN7xOp"
   },
   "outputs": [],
   "source": [
    "# test outputs of epoch = 20\n",
    "x_reconstruct_R_ep20 = vae_ep20_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_ep20 = vae_ep20_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_ep20 = vae_ep20_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_ep20 = np.transpose(np.stack((x_reconstruct_R_ep20, x_reconstruct_G_ep20, x_reconstruct_B_ep20)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EWEB5Smb8gld"
   },
   "outputs": [],
   "source": [
    "# epoch = 50\n",
    "vae_ep50_R = train_R(network_architecture, training_epochs=50, batch_size=100)\n",
    "vae_ep50_G = train_G(network_architecture, training_epochs=50, batch_size=100)\n",
    "vae_ep50_B = train_B(network_architecture, training_epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wKhf3R_AKJna"
   },
   "outputs": [],
   "source": [
    "# test outputs epoch = 50\n",
    "x_reconstruct_R_ep50 = vae_ep50_R.reconstruct(x_sample_R.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_G_ep50 = vae_ep50_G.reconstruct(x_sample_G.reshape(100,1024)).reshape(100, 32, 32)\n",
    "x_reconstruct_B_ep50 = vae_ep50_B.reconstruct(x_sample_B.reshape(100,1024)).reshape(100, 32, 32)\n",
    "\n",
    "# combine sample array\n",
    "x_reconstruct_ep50 = np.transpose(np.stack((x_reconstruct_R_ep50, x_reconstruct_G_ep50, x_reconstruct_B_ep50)), (1, 2, 3, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WAl-kP2EKVlH"
   },
   "outputs": [],
   "source": [
    "# comparison of different epochs\n",
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 4, 4*i + 1)\n",
    "    plt.imshow(x_sample[i+20])\n",
    "    plt.title(\"Test input\")\n",
    "    plt.subplot(5, 4, 4*i + 2)\n",
    "    plt.imshow(x_reconstruct[i+20])\n",
    "    plt.title(\"epoch = 10\")\n",
    "    plt.subplot(5, 4, 4*i + 3)\n",
    "    plt.imshow(x_reconstruct_ep20[i+20])\n",
    "    plt.title(\"epoch = 20\")\n",
    "    plt.subplot(5, 4, 4*i + 4)\n",
    "    plt.imshow(x_reconstruct_ep50[i+20])\n",
    "    plt.title(\"epoch = 50\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('change of epoch')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "VAE on SVHN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
